# ğŸ“š RAG Demo Application

A lightweight Retrieval-Augmented Generation (RAG) web application designed for **Render free tier deployment**. Perfect for portfolio demonstrations and technical interviews.

![RAG Architecture](https://img.shields.io/badge/Architecture-RAG-blue)
![Python](https://img.shields.io/badge/Python-3.10+-green)
![React](https://img.shields.io/badge/React-18-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ¯ Features

- **Document Upload**: Support for PDF and TXT files
- **Semantic Search**: FAISS-powered vector similarity search
- **Multi-Model Failover**: Automatic fallback across 3 free LLMs
- **Citations**: Answers include source references
- **Stateless Design**: Optimized for free tier deployment
- **Clean UI**: Simple, interview-ready interface

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend â”‚â”€â”€â”€â”€â–¶â”‚  FastAPI Backend â”‚â”€â”€â”€â”€â–¶â”‚  OpenRouter API â”‚
â”‚   (Vite)         â”‚     â”‚  (Python)        â”‚     â”‚  (Free LLMs)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   FAISS Index    â”‚
                        â”‚   (In-Memory)    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RAG Flow

1. **Upload**: Document â†’ Text Extraction â†’ Chunking â†’ Embedding â†’ FAISS Index
2. **Query**: Question â†’ Embedding â†’ Semantic Search â†’ Top-K Retrieval
3. **Generate**: Context + Question â†’ LLM (with failover) â†’ Answer + Citations

## ğŸ§  Models (Free Tier)

The application uses three OpenRouter models with automatic failover:

| Priority | Model | Context Limit | Timeout |
|----------|-------|---------------|---------|
| 1ï¸âƒ£ Primary | Hermes 3 405B | 8,000 tokens | 8s |
| 2ï¸âƒ£ Secondary | Mistral 7B | 4,000 tokens | 8s |
| 3ï¸âƒ£ Fallback | Llama 3.3 70B | 3,000 tokens | 8s |

### Failover Strategy

```
Request â†’ Model 1 (Hermes)
              â”‚
              â–¼ Timeout/Error?
          Model 2 (Mistral)
              â”‚
              â–¼ Timeout/Error?
          Model 3 (Llama)
              â”‚
              â–¼ All failed?
          Return error
```

## âš¡ Free Tier Optimizations

| Optimization | Implementation |
|-------------|----------------|
| No persistent storage | FAISS recreated on startup |
| Lightweight embeddings | all-MiniLM-L6-v2 (22M params) |
| Limited context | Max 3 chunks per query |
| Aggressive timeouts | 8 seconds per model |
| Small chunk size | 500-700 tokens |
| In-memory only | No database required |

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Node.js 18+
- OpenRouter API key ([Get free key](https://openrouter.ai/))

### Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set environment variable
export OPENROUTER_API_KEY="your-api-key-here"

# Run server
uvicorn main:app --host 0.0.0.0 --port 10000 --reload
```

### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

Open http://localhost:3000 in your browser.

## ğŸ“ Project Structure

```
rag-app/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Configuration & models
â”‚   â”œâ”€â”€ llm_router.py        # Multi-model failover
â”‚   â”œâ”€â”€ ingest.py            # Document ingestion
â”‚   â”œâ”€â”€ retriever.py         # FAISS vector store
â”‚   â”œâ”€â”€ qa.py                # RAG pipeline
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ loaders.py       # PDF/TXT extraction
â”‚   â”‚   â””â”€â”€ chunker.py       # Text chunking
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Upload.jsx   # File upload
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.jsx     # Q&A interface
â”‚   â”‚   â”‚   â””â”€â”€ Sources.jsx  # Citations display
â”‚   â”‚   â”œâ”€â”€ App.jsx          # Main component
â”‚   â”‚   â”œâ”€â”€ main.jsx         # Entry point
â”‚   â”‚   â””â”€â”€ index.css        # Styles
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â””â”€â”€ README.md
```

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API information |
| GET | `/health` | Health check |
| POST | `/upload` | Upload document |
| POST | `/ask` | Ask question |
| GET | `/stats` | System statistics |
| POST | `/clear` | Clear all documents |

### Example Requests

**Upload Document:**
```bash
curl -X POST http://localhost:10000/upload \
  -F "file=@document.pdf"
```

**Ask Question:**
```bash
curl -X POST http://localhost:10000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the main topic?", "top_k": 3}'
```

## ğŸŒ Deployment (Render)

### Backend Deployment

1. Create a new **Web Service** on Render
2. Connect your GitHub repository
3. Configure:
   - **Root Directory**: `backend`
   - **Runtime**: Python 3
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `uvicorn main:app --host 0.0.0.0 --port 10000`
4. Add environment variable:
   - `OPENROUTER_API_KEY`: Your API key

### Frontend Deployment

1. Create a new **Static Site** on Render
2. Connect your GitHub repository
3. Configure:
   - **Root Directory**: `frontend`
   - **Build Command**: `npm install && npm run build`
   - **Publish Directory**: `dist`
4. Add environment variable:
   - `VITE_API_URL`: Your backend URL (e.g., `https://your-backend.onrender.com`)

## ğŸ’¡ Example Questions

After uploading a document, try these questions:

- "What is the main topic of this document?"
- "Summarize the key points."
- "What are the conclusions mentioned?"
- "Who are the main people or organizations discussed?"
- "What dates or timeframes are mentioned?"

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENROUTER_API_KEY` | OpenRouter API key | Yes |
| `SITE_URL` | Your site URL (for OpenRouter) | No |
| `SITE_NAME` | Your site name (for OpenRouter) | No |
| `VITE_API_URL` | Backend API URL (frontend) | Production only |

### Customization

Edit `backend/config.py` to adjust:
- Chunk size and overlap
- Number of retrieved chunks
- Model priorities and timeouts
- Prompt template

## âš ï¸ Limitations

This is a **demonstration project** with intentional limitations:

- **No persistence**: Data is lost on restart
- **Memory constraints**: Limited by free tier RAM
- **Rate limits**: Subject to OpenRouter free tier limits
- **No authentication**: Open access by design
- **Single user**: Not designed for concurrent heavy usage

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | FastAPI, Python 3.10+ |
| Vector Store | FAISS (in-memory) |
| Embeddings | SentenceTransformers (all-MiniLM-L6-v2) |
| LLM API | OpenRouter (free tier) |
| Frontend | React 18, Vite |
| Styling | Plain CSS |
| Deployment | Render (free tier) |

## ğŸ“„ License

MIT License - Feel free to use for your portfolio!

## ğŸ™ Acknowledgments

- [OpenRouter](https://openrouter.ai/) for free LLM access
- [Sentence Transformers](https://sbert.net/) for embeddings
- [FAISS](https://github.com/facebookresearch/faiss) for vector search
- [FastAPI](https://fastapi.tiangolo.com/) for the backend framework
- [Vite](https://vitejs.dev/) for frontend tooling

---

**Built for learning and demonstration purposes.** Perfect for showing RAG fundamentals in interviews! ğŸ¯